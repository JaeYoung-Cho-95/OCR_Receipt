{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "from PIL import Image\n",
    "import glob\n",
    "images_path = '.././data/aug_img/'\n",
    "df = pd.read_csv('.././data/df.csv',encoding = 'utf-8',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 개수 : 750\n"
     ]
    }
   ],
   "source": [
    "label2target = {l:t+1 for t,l in enumerate(df['Label'].unique())}\n",
    "label2target['background'] = 0\n",
    "target2label = {t:l for l,t in label2target.items()}\n",
    "background_class = label2target['background']\n",
    "num_classes = len(label2target)\n",
    "print('class 개수 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 형태가 w,h,channel 형태로 되어있어서 channerl,w,h로 바꿔줘야한다.\n",
    "def preprocess_image(img):\n",
    "    img = torch.tensor(img).permute(2,0,1)\n",
    "    return img.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 열어주는 class인데, torch.utils.data.Dataset를 상속받아준다.\n",
    "class OpenDataset(torch.utils.data.Dataset):\n",
    "    # OpenDataset 속성\n",
    "    w, h = 224, 224\n",
    "    \n",
    "    def __init__(self, df : pd.DataFrame, image_dir : str = images_path):\n",
    "        \"\"\" 객체 생성 함수\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): 이미지 정보들이 저장되어 있는 데이터 프레임을 넣어주면 된다.\n",
    "            image_dir (str, optional): 이미지 경로를 넣어주면 된다.. Defaults to images_path.\n",
    "        \"\"\"        \n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        # 이미지 경로를 받아오면 경로에 있는 이미지 파일들을 self.files 라는 객체 속성값으로 받아준다.\n",
    "        self.files = glob.glob(self.image_dir+'/*')\n",
    "        self.df = df\n",
    "\n",
    "        # image_infos 객체 속성값으로 데이터 프레임의 ImageID 의 unique 값을 넣어준다. \n",
    "        self.image_infos = df.Image_Name.unique()\n",
    "\n",
    "    def __getitem__(self, ix : int) -> torch.tensor :\n",
    "        \"\"\" index 접근 함수\n",
    "\n",
    "        Args:\n",
    "            ix (int): instance에 접근하고 싶은 인덱스\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: 해당 instance 의 index 번째에 위치한 이미지 \n",
    "            torch.tensor: 해당 instance 의 index 번째에 위치한 target\n",
    "        \"\"\"        \n",
    "        # 객체 instance의 ix 번째에 위치한 이미지 이름을 먼저 받아온다.\n",
    "        image_id = self.image_infos[ix]\n",
    "\n",
    "        # 예를 들어, image_id 가 '100.jpg' 라면 self.files 안에서 '100.jpg' 가 포함된 '.././data/aug_img/100.jpg' 를 출력해준다.\n",
    "        img_path = find(image_id, self.files)\n",
    "\n",
    "        # 이미지를 열어주는 RGB값 변환 후 열어준다.\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # 이미지 크기를 class 속성에 미리 선언해준 224, 224로 변환해주고 resampling 은 BILINEAR 기법을 이용한다.\n",
    "        # 이후 이미지 색상 값들을 255로 나눠 정규화 실시\n",
    "        img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n",
    "\n",
    "        # 데이터 프레임에서 ImageID가 imgae_id(예를 들어, '100.jpg') 인 것들을 찾아 data에 할당한다.\n",
    "        data = df[df['ImageID'] == image_id]\n",
    "\n",
    "        # data에 할당된 데이터프레임에서 'Label'에 해당하는 것들을 찾아 labels에 담아준다.\n",
    "        labels = data['Label'].values.tolist()\n",
    "\n",
    "        # data에서 Xmin, Ymin, XMax, YMax 를 찾아 값들을 data에 재할당한다.\n",
    "        data = data[['Xmin','Ymin','XMax','YMax']].values\n",
    "\n",
    "        # 현재 data에는 resize 되기 전 값이 들어가 있기 때문에 사이즈에 맞게 변형해줘야한다.\n",
    "        data[:,[0,2]] *= (self.w/1500)\n",
    "        data[:,[1,3]] *= (self.h/1000)\n",
    "\n",
    "        # data는 어차피 양의 정수이기 때문에 uint32로 변형하고 list에 담아준다.\n",
    "        boxes = data.astype(np.uint32).tolist() \n",
    "\n",
    "        # torch에서 bbbox 정보는 dictionary 형식을 받는다.\n",
    "        target = {}\n",
    "\n",
    "        # torch['boxes'] 는 boundingbox의 Xmin, Ymin, XMax, YMax 값들이 들어가 있다.\n",
    "        target[\"boxes\"] = torch.Tensor(boxes).float()\n",
    "\n",
    "        # torch['labels'] 는 labels에 있는 값들을 숫자형태로 변형시켜준다.\n",
    "        target[\"labels\"] = torch.Tensor([label2target[i] for i in labels]).long()\n",
    "\n",
    "        # 현재 이미지는 w,h,channel로 들어가있기 때문에 channel, w, h 의 형태로 바꿔준다.\n",
    "        img = preprocess_image(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return tuple(zip(*batch)) \n",
    "\n",
    "    #instance의 길이정보를 원하면 이미지들의 개수를 출력해준다.\n",
    "    def __len__(self):\n",
    "        return len(self.image_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Json_Name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Xmin</th>\n",
       "      <th>Ymin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.json</td>\n",
       "      <td>신용카드전표</td>\n",
       "      <td>1501.68640</td>\n",
       "      <td>826.04950</td>\n",
       "      <td>1992.25500</td>\n",
       "      <td>1095.79480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.json</td>\n",
       "      <td>고객용</td>\n",
       "      <td>2019.32010</td>\n",
       "      <td>863.77844</td>\n",
       "      <td>2269.65280</td>\n",
       "      <td>1115.33030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.json</td>\n",
       "      <td>영수증</td>\n",
       "      <td>1248.48500</td>\n",
       "      <td>1145.79300</td>\n",
       "      <td>1478.32530</td>\n",
       "      <td>1276.87150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.json</td>\n",
       "      <td>20211226</td>\n",
       "      <td>1568.83960</td>\n",
       "      <td>1160.13260</td>\n",
       "      <td>1884.71330</td>\n",
       "      <td>1285.59910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0.json</td>\n",
       "      <td>01</td>\n",
       "      <td>1901.62120</td>\n",
       "      <td>1186.74160</td>\n",
       "      <td>1983.29300</td>\n",
       "      <td>1287.05030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107182</th>\n",
       "      <td>66933.jpg</td>\n",
       "      <td>66933.json</td>\n",
       "      <td>1</td>\n",
       "      <td>481.45120</td>\n",
       "      <td>747.88367</td>\n",
       "      <td>485.40433</td>\n",
       "      <td>757.10864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107183</th>\n",
       "      <td>66933.jpg</td>\n",
       "      <td>66933.json</td>\n",
       "      <td>층</td>\n",
       "      <td>486.41376</td>\n",
       "      <td>747.62000</td>\n",
       "      <td>493.54416</td>\n",
       "      <td>758.26890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107184</th>\n",
       "      <td>66933.jpg</td>\n",
       "      <td>66933.json</td>\n",
       "      <td>대표자</td>\n",
       "      <td>443.89963</td>\n",
       "      <td>758.25130</td>\n",
       "      <td>469.56470</td>\n",
       "      <td>769.21027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107185</th>\n",
       "      <td>66933.jpg</td>\n",
       "      <td>66933.json</td>\n",
       "      <td>이진희</td>\n",
       "      <td>477.60703</td>\n",
       "      <td>757.58620</td>\n",
       "      <td>503.55720</td>\n",
       "      <td>769.28810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107186</th>\n",
       "      <td>66933.jpg</td>\n",
       "      <td>66933.json</td>\n",
       "      <td>매출일</td>\n",
       "      <td>444.26788</td>\n",
       "      <td>769.59000</td>\n",
       "      <td>469.04750</td>\n",
       "      <td>781.40045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4107187 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image_Name   Json_Name     Label        Xmin        Ymin        XMax  \\\n",
       "0            0.jpg      0.json    신용카드전표  1501.68640   826.04950  1992.25500   \n",
       "1            0.jpg      0.json       고객용  2019.32010   863.77844  2269.65280   \n",
       "2            0.jpg      0.json       영수증  1248.48500  1145.79300  1478.32530   \n",
       "3            0.jpg      0.json  20211226  1568.83960  1160.13260  1884.71330   \n",
       "4            0.jpg      0.json        01  1901.62120  1186.74160  1983.29300   \n",
       "...            ...         ...       ...         ...         ...         ...   \n",
       "4107182  66933.jpg  66933.json         1   481.45120   747.88367   485.40433   \n",
       "4107183  66933.jpg  66933.json         층   486.41376   747.62000   493.54416   \n",
       "4107184  66933.jpg  66933.json       대표자   443.89963   758.25130   469.56470   \n",
       "4107185  66933.jpg  66933.json       이진희   477.60703   757.58620   503.55720   \n",
       "4107186  66933.jpg  66933.json       매출일   444.26788   769.59000   469.04750   \n",
       "\n",
       "               YMax  \n",
       "0        1095.79480  \n",
       "1        1115.33030  \n",
       "2        1276.87150  \n",
       "3        1285.59910  \n",
       "4        1287.05030  \n",
       "...             ...  \n",
       "4107182   757.10864  \n",
       "4107183   758.26890  \n",
       "4107184   769.21027  \n",
       "4107185   769.28810  \n",
       "4107186   781.40045  \n",
       "\n",
       "[4107187 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702977 404210\n"
     ]
    }
   ],
   "source": [
    "# 데이터 나눠주기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 프레임의 df.Image_Name 들의 unique 값들을 기준으로 test_size는 0.1로 하여 나눈다.\n",
    "trn_ids, val_ids = train_test_split(df.Image_Name.unique(), test_size=0.1, random_state=99)\n",
    "\n",
    "# train_df, val_df 를 나눠준다.\n",
    "trn_df, val_df = df[df['Image_Name'].isin(trn_ids)], df[df['Image_Name'].isin(val_ids)]\n",
    "\n",
    "print(len(trn_df), len(val_df))\n",
    "\n",
    "train_ds = OpenDataset(trn_df)\n",
    "test_ds = OpenDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, collate_fn=train_ds.collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, collate_fn=test_ds.collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training and validation functions for a single batch\n",
    "def train_batch(inputs, model, optimizer):\n",
    "    model.train()\n",
    "    input, targets = inputs\n",
    "    input = list(image.to(device) for image in input)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(input, targets)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, losses\n",
    "\n",
    "@torch.no_grad() # this will disable gradient computation in the function below\n",
    "def validate_batch(inputs, model):\n",
    "    model.train() # to obtain the losses, model needs to be in train mode only. # #Note that here we are not defining the model's forward method \n",
    "#and hence need to work per the way the model class is defined\n",
    "    input, targets = inputs\n",
    "    input = list(image.to(device) for image in input)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(input, targets)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "n_epochs = 5\n",
    "log = Report(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    _n = len(train_loader)\n",
    "    for ix, inputs in enumerate(train_loader):\n",
    "        loss, losses = train_batch(inputs, model, optimizer)\n",
    "        loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\n",
    "            [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\n",
    "        pos = (epoch + (ix+1)/_n)\n",
    "        log.record(pos, trn_loss=loss.item(), trn_loc_loss=loc_loss.item(), \n",
    "                   trn_regr_loss=regr_loss.item(), trn_objectness_loss=loss_objectness.item(),\n",
    "                   trn_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\n",
    "\n",
    "    _n = len(test_loader)\n",
    "    for ix,inputs in enumerate(test_loader):\n",
    "        loss, losses = validate_batch(inputs, model)\n",
    "        loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\n",
    "          [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\n",
    "        pos = (epoch + (ix+1)/_n)\n",
    "        log.record(pos, val_loss=loss.item(), val_loc_loss=loc_loss.item(), \n",
    "                  val_regr_loss=regr_loss.item(), val_objectness_loss=loss_objectness.item(),\n",
    "                  val_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\n",
    "    if (epoch+1)%(n_epochs//5)==0: log.report_avgs(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.plot_epochs(['trn_loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import nms\n",
    "def decode_output(output):\n",
    "    'convert tensors to numpy arrays'\n",
    "    bbs = output['boxes'].cpu().detach().numpy().astype(np.uint16)\n",
    "    labels = np.array([target2label[i] for i in output['labels'].cpu().detach().numpy()])\n",
    "    confs = output['scores'].cpu().detach().numpy()\n",
    "    ixs = nms(torch.tensor(bbs.astype(np.float32)), torch.tensor(confs), 0.05)\n",
    "    bbs, confs, labels = [tensor[ixs] for tensor in [bbs, confs, labels]]\n",
    "\n",
    "    if len(ixs) == 1:\n",
    "        bbs, confs, labels = [np.array([tensor]) for tensor in [bbs, confs, labels]]\n",
    "    return bbs.tolist(), confs.tolist(), labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for ix, (images, targets) in enumerate(test_loader):\n",
    "    if ix==3: break\n",
    "    images = [im for im in images]\n",
    "    outputs = model(images)\n",
    "    for ix, output in enumerate(outputs):\n",
    "        bbs, confs, labels = decode_output(output)\n",
    "        info = [f'{l}@{c:.2f}' for l,c in zip(labels, confs)]\n",
    "        show(images[ix].cpu().permute(1,2,0), bbs=bbs, texts=labels, sz=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fc5174242677b8c456c11fc68770090ec9f6af4088f2eb802fc01b281a20ea2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('OCR_Receipt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
